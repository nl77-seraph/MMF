"""
éªŒè¯æ”¯æŒé›†æ•°æ®å®Œæ•´æ€§çš„è„šæœ¬
æ£€æŸ¥pickleæ–‡ä»¶æ ¼å¼å’Œæ•°æ®å†…å®¹
"""

import os
import pickle
import numpy as np
from tqdm import tqdm

def verify_pickle_file(file_path):
    """éªŒè¯å•ä¸ªpickleæ–‡ä»¶"""
    try:
        with open(file_path, 'rb') as f:
            sample = pickle.load(f)
        
        # æ£€æŸ¥å¿…è¦å­—æ®µ
        if 'data' not in sample or 'time' not in sample:
            return False, f"ç¼ºå°‘å¿…è¦å­—æ®µ: {list(sample.keys())}"
        
        # æ£€æŸ¥æ•°æ®ç±»å‹å’Œé•¿åº¦
        data = sample['data']
        time = sample['time']
        
        if len(data) != len(time):
            return False, f"æ•°æ®é•¿åº¦ä¸åŒ¹é…: data={len(data)}, time={len(time)}"
        
        if len(data) == 0:
            return False, "æ•°æ®ä¸ºç©º"
            
        return True, f"æ•°æ®é•¿åº¦: {len(data)}"
        
    except Exception as e:
        return False, f"è¯»å–é”™è¯¯: {str(e)}"

def verify_support_data(support_data_dir):
    """éªŒè¯æ•´ä¸ªæ”¯æŒé›†æ•°æ®ç›®å½•"""
    print(f"å¼€å§‹éªŒè¯æ”¯æŒé›†æ•°æ®: {support_data_dir}")
    
    # ç»Ÿè®¡ä¿¡æ¯
    total_files = 0
    valid_files = 0
    error_files = []
    
    # æ£€æŸ¥æ¯ä¸ªç±»åˆ«
    for class_id in range(60):  # 0-59ç±»åˆ«
        class_dir = os.path.join(support_data_dir, str(class_id))
        
        if not os.path.exists(class_dir):
            print(f"âŒ ç±»åˆ«{class_id}ç›®å½•ä¸å­˜åœ¨")
            continue
        
        # æ£€æŸ¥è¯¥ç±»åˆ«çš„æ‰€æœ‰æ–‡ä»¶
        pkl_files = [f for f in os.listdir(class_dir) if f.endswith('.pkl')]
        
        if len(pkl_files) != 50:
            print(f"âš ï¸  ç±»åˆ«{class_id}æ ·æœ¬æ•°é‡å¼‚å¸¸: {len(pkl_files)} (æœŸæœ›50)")
        
        print(f"éªŒè¯ç±»åˆ«{class_id}: {len(pkl_files)}ä¸ªæ–‡ä»¶")
        
        for pkl_file in tqdm(pkl_files, desc=f"ç±»åˆ«{class_id}", leave=False):
            file_path = os.path.join(class_dir, pkl_file)
            total_files += 1
            
            is_valid, message = verify_pickle_file(file_path)
            
            if is_valid:
                valid_files += 1
            else:
                error_files.append((file_path, message))
                if len(error_files) <= 5:  # åªæ˜¾ç¤ºå‰5ä¸ªé”™è¯¯
                    print(f"  âŒ {pkl_file}: {message}")
    
    # è¾“å‡ºç»Ÿè®¡ç»“æœ
    print(f"\nğŸ“Š éªŒè¯ç»“æœç»Ÿè®¡:")
    print(f"  - æ€»æ–‡ä»¶æ•°: {total_files}")
    print(f"  - æœ‰æ•ˆæ–‡ä»¶: {valid_files}")
    print(f"  - é”™è¯¯æ–‡ä»¶: {len(error_files)}")
    print(f"  - æˆåŠŸç‡: {valid_files/total_files*100:.2f}%")
    
    if error_files:
        print(f"\nâŒ é”™è¯¯æ–‡ä»¶åˆ—è¡¨ (æ˜¾ç¤ºå‰10ä¸ª):")
        for i, (file_path, error) in enumerate(error_files[:10]):
            print(f"  {i+1}. {file_path}: {error}")
    
    return total_files, valid_files, error_files

def sample_data_inspection(support_data_dir):
    """æŠ½æ ·æ£€æŸ¥æ•°æ®å†…å®¹"""
    print(f"\nğŸ” æŠ½æ ·æ£€æŸ¥æ•°æ®å†…å®¹:")
    
    # éšæœºé€‰æ‹©å‡ ä¸ªæ–‡ä»¶è¿›è¡Œè¯¦ç»†æ£€æŸ¥
    sample_files = [
        "datasets/3tab_exp/base_train/support_data/0/sample_0.pkl",
        "datasets/3tab_exp/base_train/support_data/30/sample_15.pkl",
        "datasets/3tab_exp/base_train/support_data/59/sample_25.pkl"
    ]
    
    for file_path in sample_files:
        if os.path.exists(file_path):
            try:
                with open(file_path, 'rb') as f:
                    sample = pickle.load(f)
                
                data = sample['data']
                time = sample['time']
                
                print(f"\nğŸ“ {file_path}:")
                print(f"  - æ•°æ®é•¿åº¦: {len(data)}")
                print(f"  - æ•°æ®èŒƒå›´: [{np.min(data):.3f}, {np.max(data):.3f}]")
                print(f"  - æ—¶é—´èŒƒå›´: [{np.min(time):.3f}, {np.max(time):.3f}]")
                print(f"  - æ•°æ®ç±»å‹: {type(data)}, {type(time)}")
                print(f"  - å‰5ä¸ªæ•°æ®å€¼: {data[:5]}")
                print(f"  - å‰5ä¸ªæ—¶é—´å€¼: {time[:5]}")
                
            except Exception as e:
                print(f"  âŒ è¯»å–å¤±è´¥: {e}")

if __name__ == "__main__":
    support_data_dir = "datasets/3tab_exp/base_train/support_data"
    
    # éªŒè¯æ•°æ®å®Œæ•´æ€§
    total_files, valid_files, error_files = verify_support_data(support_data_dir)
    
    # æŠ½æ ·æ£€æŸ¥æ•°æ®å†…å®¹
    sample_data_inspection("./")
    
    # æœ€ç»ˆæŠ¥å‘Š
    print(f"\nğŸ¯ éªŒè¯å®Œæˆï¼")
    if len(error_files) == 0:
        print("âœ… æ‰€æœ‰æ•°æ®æ–‡ä»¶éªŒè¯é€šè¿‡ï¼Œå¯ä»¥è¿›è¡Œä¸‹ä¸€æ­¥æ“ä½œ")
    else:
        print(f"âš ï¸  å‘ç°{len(error_files)}ä¸ªé—®é¢˜æ–‡ä»¶ï¼Œå»ºè®®æ£€æŸ¥å’Œä¿®å¤") 