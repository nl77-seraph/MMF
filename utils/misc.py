import torch
import torch.nn as nn
import torch.optim as optim
import torch.distributed as dist
import torch.multiprocessing as mp
from torch.nn.parallel import DistributedDataParallel as DDP
from torch.utils.data.distributed import DistributedSampler
from torch.utils.tensorboard import SummaryWriter
import numpy as np
import os
import sys
import time
import json
from datetime import datetime
import argparse
from tqdm import tqdm
import random
import warnings
warnings.filterwarnings('ignore')

# æ·»åŠ æ¨¡å—è·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))
def setup_distributed_training(rank, world_size, config):
    """
    è®¾ç½®åˆ†å¸ƒå¼è®­ç»ƒç¯å¢ƒ
    
    Args:
        rank: å½“å‰è¿›ç¨‹çš„rank
        world_size: æ€»è¿›ç¨‹æ•°
        config: é…ç½®å­—å…¸
    """
    # è®¾ç½®CUDAè®¾å¤‡
    torch.cuda.set_device(rank)
    
    # åˆå§‹åŒ–è¿›ç¨‹ç»„
    os.environ['MASTER_ADDR'] = config.get('master_addr', 'localhost')
    os.environ['MASTER_PORT'] = config.get('master_port', '12355')
    
    dist.init_process_group(
        backend=config.get('dist_backend', 'nccl'),
        init_method='env://',
        world_size=world_size,
        rank=rank
    )
    
    print(f"ğŸš€ åˆ†å¸ƒå¼è®­ç»ƒåˆå§‹åŒ–å®Œæˆ - Rank: {rank}/{world_size}")

def setup_seed(seed):
     torch.manual_seed(seed)
     torch.cuda.manual_seed_all(seed)
     np.random.seed(seed)
     random.seed(seed)
     torch.backends.cudnn.deterministic = True



def cleanup_distributed_training():
    """æ¸…ç†åˆ†å¸ƒå¼è®­ç»ƒç¯å¢ƒ"""
    if dist.is_initialized():
        dist.destroy_process_group()


def is_main_process():
    """æ£€æŸ¥æ˜¯å¦ä¸ºä¸»è¿›ç¨‹"""
    return not dist.is_initialized() or dist.get_rank() == 0

def validate_gpu_config(config):
    """
    éªŒè¯GPUé…ç½®çš„åˆæ³•æ€§
    
    Args:
        config: é…ç½®å­—å…¸
        
    Returns:
        validated_config: éªŒè¯åçš„é…ç½®
        is_valid: æ˜¯å¦æœ‰æ•ˆ
        error_msg: é”™è¯¯ä¿¡æ¯
    """
    try:
        # æ£€æŸ¥æ˜¯å¦æœ‰CUDAæ”¯æŒ
        if not torch.cuda.is_available():
            if config.get('use_distributed', False):
                return config, False, "âŒ CUDAä¸å¯ç”¨ï¼Œæ— æ³•è¿›è¡ŒGPUè®­ç»ƒ"
            else:
                print("âš ï¸ CUDAä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨CPUè®­ç»ƒ")
                config['use_distributed'] = False
                return config, True, ""
        
        # æ£€æŸ¥GPUæ•°é‡
        available_gpus = torch.cuda.device_count()
        print(f"ğŸ” æ£€æµ‹åˆ° {available_gpus} ä¸ªGPU")
        
        # éªŒè¯è¯·æ±‚çš„GPUæ˜¯å¦å­˜åœ¨
        requested_gpus = config.get('gpus', [0])
        if not isinstance(requested_gpus, list):
            return config, False, "âŒ 'gpus' é…ç½®å¿…é¡»æ˜¯åˆ—è¡¨"
        
        for gpu_id in requested_gpus:
            if gpu_id >= available_gpus:
                return config, False, f"âŒ GPU {gpu_id} ä¸å­˜åœ¨ï¼ˆåªæœ‰ {available_gpus} ä¸ªGPUï¼‰"
        
        # è®¾ç½®åˆ†å¸ƒå¼è®­ç»ƒæ¨¡å¼
        num_gpus = len(requested_gpus)
        if num_gpus > 1:
            config['use_distributed'] = True
            print(f"âœ… å°†ä½¿ç”¨ {num_gpus} ä¸ªGPUè¿›è¡Œåˆ†å¸ƒå¼è®­ç»ƒ: {requested_gpus}")
        else:
            config['use_distributed'] = False
            print(f"âœ… å°†ä½¿ç”¨å•GPUè®­ç»ƒ: GPU {requested_gpus[0]}")
        
        return config, True, ""
        
    except Exception as e:
        return config, False, f"âŒ GPUé…ç½®éªŒè¯å¤±è´¥: {e}"


def get_args():
    parser = argparse.ArgumentParser(description='Enhanced Training with Mixed Scheme C')
    parser.add_argument('--config', type=str, default='configs/config.json',help='é…ç½®æ–‡ä»¶è·¯å¾„')
    
    
    args = parser.parse_args()
    return args

def get_final_config():
    config = {}
    # åŠ è½½é…ç½®æ–‡ä»¶
    args = get_args()
    if os.path.exists(args.config):
        with open(args.config, 'r') as f:
            user_config = json.load(f)
            config.update(user_config)
    else:
        print('è¯·æ£€æŸ¥é…ç½®æ–‡ä»¶')
    
    # éªŒè¯GPUé…ç½®
    config, is_valid, error_msg = validate_gpu_config(config)
    if not is_valid:
        print(error_msg)
        return

    print("å¼€å§‹è®­ç»ƒ...")
    print(f"ğŸ“‹ é…ç½®:")
    print(f"  - åˆ†å¸ƒå¼: {config['use_distributed']}")
    print(f"  - GPU: {config['gpus']}")
    print(f"  - DFä½¿ç”¨SE: {config['use_se_in_df']}")
    
    return config
if __name__ == '__main__':
    print("test_config")
    config_path = 'config.json'
    with open(config_path, 'r') as f:
        config = json.load(f)
    print(config)




