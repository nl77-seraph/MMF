"""
ä¼˜åŒ–ç‰ˆç‰¹å¾æå–å™¨ - Base Trainingä¼˜åŒ–
ä¸»è¦ä¼˜åŒ–:
1. ç®€åŒ–MetaLearnet - å‚è€ƒFewshot_Detectionçš„è½»é‡è®¾è®¡
2. å¹¶è¡ŒåŒ–Classification Head
3. ç§»é™¤Cross-Class Attention (å¯é€‰å¼€å¯)
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
from typing import List, Dict, Tuple, Optional
import sys
import os

sys.path.append(os.path.dirname(os.path.abspath(__file__)))
from dynamic_conv1d import FeatureReweightingModule

import torch.distributed as dist

def is_main_process():
    return not dist.is_initialized() or dist.get_rank() == 0


class Dividing(nn.Module):
    """å°†é•¿åºåˆ—åˆ‡åˆ†ä¸ºå¤šä¸ªæ®µ"""
    def __init__(self, num_segments):
        super(Dividing, self).__init__()
        self.num_segments = num_segments

    def forward(self, x):
        B, C, L = x.shape
        p = L // self.num_segments
        x = x.view(B, C, self.num_segments, p)
        x = x.permute(0, 2, 1, 3).contiguous()
        x = x.view(B * self.num_segments, C, p)
        return x


class Combination(nn.Module):
    """å°†å¤šä¸ªæ®µåˆå¹¶å›é•¿åºåˆ—"""
    def __init__(self, num_segments):
        super(Combination, self).__init__()
        self.num_segments = num_segments

    def forward(self, x):
        Bn, C, p = x.shape
        B = Bn // self.num_segments
        x = x.view(B, self.num_segments, C, p)
        x = x.permute(0, 2, 1, 3).contiguous()
        x = x.view(B, C, self.num_segments * p)
        return x


class ConvBlock1d(nn.Module):
    def __init__(self, in_channels, out_channels, kernel_size, dilation=1):
        super(ConvBlock1d, self).__init__()
        self.net = nn.Sequential(
            nn.Conv1d(in_channels, out_channels, kernel_size, dilation=dilation, padding="same"),
            nn.BatchNorm1d(out_channels),
            nn.ReLU(),
            nn.Conv1d(out_channels, out_channels, kernel_size, dilation=dilation, padding="same"),
            nn.BatchNorm1d(out_channels),
            nn.ReLU()
        )
        self.downsample = nn.Conv1d(in_channels, out_channels, 1) if in_channels != out_channels else None
        if self.downsample is not None:
            self.downsample.weight.data.normal_(0, 0.01)
        self.last_relu = nn.ReLU()

    def forward(self, x):
        out = self.net(x)
        res = x if self.downsample is None else self.downsample(x)
        return self.last_relu(out + res)


class LocalProfiling(nn.Module):
    """Local Profiling module - æŸ¥è¯¢é›†ç‰¹å¾æå–"""
    def __init__(self, in_channels):
        super(LocalProfiling, self).__init__()
        self.net = nn.Sequential(
            ConvBlock1d(in_channels, 32, kernel_size=7),
            nn.MaxPool1d(kernel_size=8, stride=4),
            nn.Dropout(p=0.1),
            ConvBlock1d(32, 64, kernel_size=7),
            nn.MaxPool1d(kernel_size=8, stride=4),
            nn.Dropout(p=0.1),
            ConvBlock1d(64, 128, kernel_size=7),
            nn.MaxPool1d(kernel_size=8, stride=4),
            nn.Dropout(p=0.1),
            ConvBlock1d(128, 256, kernel_size=7),
            nn.MaxPool1d(kernel_size=8, stride=4),
            nn.Dropout(p=0.1),
        )
        self.out_channels = 256

    def forward(self, x):
        return self.net(x)


class ARESBackbone(nn.Module):
    """æŸ¥è¯¢é›†Backbone: åˆ†æ®µ -> CNN -> åˆå¹¶"""
    def __init__(self, in_channels=1, num_segments=4):
        super(ARESBackbone, self).__init__()
        self.num_segments = num_segments
        self.dividing = Dividing(num_segments)
        self.profiling = LocalProfiling(in_channels)
        self.combination = Combination(num_segments)
        self.out_channels = self.profiling.out_channels

    def forward(self, x):
        x = self.dividing(x)
        x = self.profiling(x)
        x = self.combination(x)
        return x


# ============= ç®€åŒ–ç‰ˆ MetaLearnet =============
class LightweightMetaLearnet(nn.Module):
    """
    è½»é‡çº§MetaLearnet - å‚è€ƒFewshot_Detectionçš„è®¾è®¡
    
    å…³é”®ç®€åŒ–:
    1. ä¸ä½¿ç”¨åˆ†æ®µå¤„ç†ï¼ˆARESçš„Dividing/Combinationï¼‰
    2. ä½¿ç”¨æ›´å°‘çš„å·ç§¯å±‚
    3. ç›´æ¥GlobalMaxPoolæå–å…¨å±€ç‰¹å¾
    
    è¿™æ ·è®¾è®¡çš„å¥½å¤„:
    1. è®¡ç®—é‡å¤§å¹…å‡å°‘
    2. æ›´å®¹æ˜“é€‚é…novel classes (few-shoté˜¶æ®µ)
    3. ä¿æŒä¸Fewshot_Detectionä¸€è‡´çš„è®¾è®¡æ€è·¯
    """
    
    def __init__(self, in_channels: int, out_channels: int, dropout: float = 0.3):
        super(LightweightMetaLearnet, self).__init__()
        
        self.out_channels = out_channels
        
        # ç®€åŒ–çš„CNN backbone - å‚è€ƒreweighting_net.cfgçš„è®¾è®¡
        # è¾“å…¥: (batch, 2, length) å…¶ä¸­ channel 0=data, channel 1=mask
        self.backbone = nn.Sequential(
            # Block 1: 32 channels
            nn.Conv1d(in_channels, 32, kernel_size=7, stride=1, padding=3),
            nn.BatchNorm1d(32),
            nn.LeakyReLU(0.1),
            nn.MaxPool1d(kernel_size=4, stride=4),
            
            # Block 2: 64 channels  
            nn.Conv1d(32, 64, kernel_size=5, stride=1, padding=2),
            nn.BatchNorm1d(64),
            nn.LeakyReLU(0.1),
            nn.MaxPool1d(kernel_size=4, stride=4),
            
            # Block 3: 128 channels
            nn.Conv1d(64, 128, kernel_size=5, stride=1, padding=2),
            nn.BatchNorm1d(128),
            nn.LeakyReLU(0.1),
            nn.MaxPool1d(kernel_size=4, stride=4),
            
            # Block 4: 256 channels
            nn.Conv1d(128, 256, kernel_size=3, stride=1, padding=1),
            nn.BatchNorm1d(256),
            nn.LeakyReLU(0.1),
            nn.MaxPool1d(kernel_size=4, stride=4),
            
            # Block 5: 256 channels
            nn.Conv1d(256, 256, kernel_size=3, stride=1, padding=1),
            nn.BatchNorm1d(256),
            nn.LeakyReLU(0.1),
        )
        
        # GlobalMaxPool - ä¸Fewshot_Detectionä¸€è‡´
        self.global_pool = nn.AdaptiveMaxPool1d(1)
        
        # ç®€åŒ–çš„æƒé‡ç”Ÿæˆå™¨
        self.weight_generator = nn.Sequential(
            nn.Linear(256, out_channels),
            nn.LayerNorm(out_channels)
        )
    
    def forward(self, x):
        """
        Args:
            x: (num_classes, shots, 2, length)
        Returns:
            åŠ¨æ€æƒé‡: (num_classes, out_channels)
        """
        num_classes, shots, channels, length = x.shape
        
        # Reshape: (num_classes * shots, 2, length)
        x = x.view(num_classes * shots, channels, length)
        
        # CNNç‰¹å¾æå–
        features = self.backbone(x)  # (num_classes * shots, 256, L')
        
        # GlobalMaxPool
        pooled = self.global_pool(features).squeeze(-1)  # (num_classes * shots, 256)
        
        # Reshapeå¹¶å–meanèåˆshots
        pooled = pooled.view(num_classes, shots, -1)  # (num_classes, shots, 256)
        pooled = pooled.mean(dim=1)  # (num_classes, 256)
        
        # ç”ŸæˆåŠ¨æ€æƒé‡
        weights = self.weight_generator(pooled)  # (num_classes, out_channels)
        
        return weights


# ============= ä¼˜åŒ–ç‰ˆ Classification Head =============
class OptimizedClassificationHead(nn.Module):
    """
    ä¼˜åŒ–çš„åˆ†ç±»å¤´
    
    ä¸»è¦ä¼˜åŒ–:
    1. TopM Attention å¹¶è¡Œå¤„ç†æ‰€æœ‰ç±»åˆ«ï¼ˆä¸å†ä¸²è¡Œå¾ªç¯ï¼‰
    2. å¯é€‰å…³é—­ Cross-Class Attention
    3. ç®€åŒ–çš„åˆ†ç±»å™¨
    """
    
    def __init__(self, feature_dim: int = 256, num_classes: int = 60, seq_len: int = 72,
                 num_topm_layers: int = 2, use_cross_attention: bool = False,
                 num_cross_layers: int = 1, dropout: float = 0.1,
                 use_cosine_classifier: bool = False):
        super(OptimizedClassificationHead, self).__init__()
        
        self.feature_dim = feature_dim
        self.num_classes = num_classes
        self.seq_len = seq_len
        self.num_topm_layers = num_topm_layers
        self.use_cross_attention = use_cross_attention
        self.use_cosine_classifier = use_cosine_classifier
        num_heads = 8
        top_m = min(20, seq_len)
        
        # ä½ç½®ç¼–ç  - æ‰€æœ‰ç±»åˆ«å…±äº«
        self.pos_embed = nn.Parameter(torch.randn(1, seq_len, feature_dim) * 0.02)
        
        # TopM Attentionå±‚
        self.topm_layers = nn.ModuleList([
            OptimizedTopMAttention(feature_dim, num_heads, dropout, top_m)
            for _ in range(num_topm_layers)
        ])
        self.topm_norms = nn.ModuleList([
            nn.LayerNorm(feature_dim) for _ in range(num_topm_layers)
        ])
        
        # Cross-Class Attention (å¯é€‰)
        if use_cross_attention:
            self.cross_attn = nn.MultiheadAttention(
                embed_dim=feature_dim, num_heads=num_heads,
                dropout=dropout, batch_first=True
            )
            self.cross_norm = nn.LayerNorm(feature_dim)
        
        # ç®€åŒ–çš„åˆ†ç±»å™¨
        self.classifier = nn.Sequential(
            nn.Linear(feature_dim, feature_dim // 2),
            nn.ReLU(inplace=True),
            nn.Dropout(dropout),
            nn.Linear(feature_dim // 2, 1),
        )
        if use_cosine_classifier:
            # æ¯ä¸ªç±»ä¸€ä¸ª prototype + ä¸€ä¸ªå…¨å±€ scale
            self.class_prototypes = nn.Parameter(
                torch.randn(num_classes, feature_dim)
            )
            self.scale = nn.Parameter(torch.tensor(10.0))
        
        if is_main_process():
            print(f"OptimizedClassificationHead:")
            print(f"  - TopMå±‚æ•°: {num_topm_layers}")
            print(f"  - Cross-Attention: {'å¼€å¯' if use_cross_attention else 'å…³é—­'}")
            print(f"  - åºåˆ—é•¿åº¦: {seq_len}")
            print(f"  - ä½¿ç”¨ä½™å¼¦ç›¸ä¼¼åº¦åˆ†ç±»å™¨: {'å¼€å¯' if use_cosine_classifier else 'å…³é—­'}")
    
    def forward(self, reweighted_features):
        """
        å¹¶è¡Œå¤„ç†æ‰€æœ‰ç±»åˆ«
        
        Args:
            reweighted_features: (batch * num_classes, feature_dim, seq_len)
        Returns:
            logits: (batch, num_classes)
        """
        batch_times_classes, feature_dim, seq_len = reweighted_features.shape
        batch_size = batch_times_classes // self.num_classes
        
        # è½¬ç½®: (batch * num_classes, seq_len, feature_dim)
        x = reweighted_features.transpose(1, 2)
        
        # æ·»åŠ ä½ç½®ç¼–ç 
        x = x + self.pos_embed
        
        # TopM Attention - æ‰€æœ‰ç±»åˆ«å¹¶è¡Œå¤„ç†
        for i in range(self.num_topm_layers):
            x = x + self.topm_layers[i](x)
            x = self.topm_norms[i](x)
        
        # å…¨å±€å¹³å‡æ± åŒ–: (batch * num_classes, seq_len, feature_dim) â†’ (batch * num_classes, feature_dim)
        x = x.mean(dim=1)
        x = x.view(batch_size, self.num_classes, feature_dim)
        # å¯é€‰çš„Cross-Class Attention
        if self.use_cross_attention:
            # Reshape: (batch, num_classes, feature_dim)
            x = x.view(batch_size, self.num_classes, feature_dim)
            attn_out, _ = self.cross_attn(x, x, x)
            x = self.cross_norm(x + attn_out)
            x = x.view(batch_size * self.num_classes, feature_dim)
        
        if self.use_cosine_classifier:
            # ä½™å¼¦ç›¸ä¼¼åº¦ per class
            # x: (B, C, F)   prototypes: (C, F)
            x_norm = F.normalize(x, p=2, dim=-1)       # (B, C, F)
            w_norm = F.normalize(self.class_prototypes, p=2, dim=-1)  # (C, F)

            # å†…ç§¯ï¼šå¯¹æœ€åä¸€ç»´æ±‚å’Œ
            logits = (x_norm * w_norm.unsqueeze(0)).sum(dim=-1)       # (B, C)
            logits = self.scale * logits
        else:
            # åŸæ¥çš„å…±äº« MLP è·¯å¾„
            x_flat = x.view(batch_size, self.num_classes, feature_dim)        # (B*C, F)
            logits = self.classifier(x_flat)                          # (B*C, 1)
            logits = logits.view(batch_size, self.num_classes)
        
        return logits


class OptimizedTopMAttention(nn.Module):
    """ä¼˜åŒ–çš„TopM Attention"""
    
    def __init__(self, dim: int, num_heads: int, dropout: float, top_m: int):
        super().__init__()
        self.num_heads = num_heads
        self.head_dim = dim // num_heads
        self.scale = self.head_dim ** -0.5
        self.top_m = top_m
        
        self.qkv = nn.Linear(dim, dim * 3)
        self.proj = nn.Linear(dim, dim)
        self.dropout = nn.Dropout(dropout)
    
    def forward(self, x):
        B, N, C = x.shape
        
        qkv = self.qkv(x).reshape(B, N, 3, self.num_heads, self.head_dim).permute(2, 0, 3, 1, 4)
        q, k, v = qkv[0], qkv[1], qkv[2]
        
        # è®¡ç®—æ³¨æ„åŠ›åˆ†æ•°
        attn = (q @ k.transpose(-2, -1)) * self.scale
        
        # TopM masking
        if self.top_m < N:
            topk_indices = torch.topk(attn, k=self.top_m, dim=-1)[1]
            mask = torch.zeros_like(attn)
            mask.scatter_(-1, topk_indices, 1.0)
            attn = attn.masked_fill(mask == 0, float('-inf'))
        
        attn = F.softmax(attn, dim=-1)
        attn = self.dropout(attn)
        
        x = (attn @ v).transpose(1, 2).reshape(B, N, C)
        x = self.proj(x)
        
        return x


# ============= ä¼˜åŒ–ç‰ˆä¸»ç½‘ç»œ =============
class OptimizedMultiMetaFingerNet(nn.Module):
    """
    ä¼˜åŒ–ç‰ˆå¤šæ ‡ç­¾å…ƒæŒ‡çº¹è¯†åˆ«ç½‘ç»œ
    
    ä¼˜åŒ–ç‚¹:
    1. LightweightMetaLearnet - ç®€åŒ–æ”¯æŒé›†å¤„ç†
    2. OptimizedClassificationHead - å¹¶è¡ŒåŒ–åˆ†ç±»å¤´
    3. å¯é…ç½®çš„Cross-Attentionå¼€å…³
    """
    
    def __init__(self, num_classes: int = 60, dropout: float = 0.15,
                 use_cross_attention: bool = False,
                 num_topm_layers: int = 2,
                 meta_learnet_type: str = 'lightweight',
                 use_cosine_classifier: bool = False):  # 'lightweight' or 'full'
        super(OptimizedMultiMetaFingerNet, self).__init__()
        
        self.num_classes = num_classes
        
        # 1. æŸ¥è¯¢é›†ç‰¹å¾æå– - ä¿æŒARES Backbone
        self.feature_extractor = ARESBackbone(in_channels=1, num_segments=4)
        self.query_feature_dim = self.feature_extractor.out_channels  # 256
        
        # 2. MetaLearnet - ä½¿ç”¨è½»é‡ç‰ˆ
        if meta_learnet_type == 'lightweight':
            self.meta_learnet = LightweightMetaLearnet(
                in_channels=2,  # data + mask
                out_channels=self.query_feature_dim,
                dropout=dropout
            )
        else:
            # ä¿ç•™å®Œæ•´ç‰ˆé€‰é¡¹
            from feature_extractors_enhanced import EnhancedMetaLearnet
            self.meta_learnet = EnhancedMetaLearnet(
                in_channels=2,
                out_channels=self.query_feature_dim,
                dropout=dropout
            )
        
        # 3. ç‰¹å¾é‡åŠ æƒ - 1DåŠ¨æ€å·ç§¯
        self.feature_reweighting = FeatureReweightingModule(
            feature_dim=self.query_feature_dim,
            kernel_size=1
        )
        
        # 4. ä¼˜åŒ–çš„åˆ†ç±»å¤´
        self.classification_head = OptimizedClassificationHead(
            feature_dim=self.query_feature_dim,
            num_classes=num_classes,
            seq_len=72,
            num_topm_layers=num_topm_layers,
            use_cross_attention=use_cross_attention,
            dropout=dropout,
            use_cosine_classifier=use_cosine_classifier
        )
        
        if is_main_process():
            self._print_model_info()
    
    def _print_model_info(self):
        total_params = sum(p.numel() for p in self.parameters())
        trainable_params = sum(p.numel() for p in self.parameters() if p.requires_grad)
        print(f"\nğŸš€ OptimizedMultiMetaFingerNet:")
        print(f"  - æ€»å‚æ•°: {total_params:,}")
        print(f"  - å¯è®­ç»ƒ: {trainable_params:,}")
    
    def forward(self, query_data, support_data, support_masks=None):
        """
        Args:
            query_data: (batch, length) æˆ– (batch, 1, length)
            support_data: (num_classes, shots, length)
            support_masks: (num_classes, shots, length)
        Returns:
            dict with logits and intermediate features
        """
        # æŸ¥è¯¢é›†ç‰¹å¾æå–
        if len(query_data.shape) == 2:
            query_data = query_data.unsqueeze(1)
        query_features = self.feature_extractor(query_data)  # (batch, 256, seq_len)
        query_features = query_features.transpose(1, 2)  # (batch, seq_len, 256)
        
        # æ”¯æŒé›†åŠ¨æ€æƒé‡ç”Ÿæˆ
        if support_masks is None:
            support_masks = torch.ones_like(support_data)
        support_input = torch.stack([support_data, support_masks], dim=2)  # (num_classes, shots, 2, length)
        dynamic_weights = self.meta_learnet(support_input)  # (num_classes, 256)
        
        # ç‰¹å¾èåˆï¼ˆ1DåŠ¨æ€å·ç§¯ï¼‰
        reweighted_features = self.feature_reweighting(query_features, dynamic_weights)
        
        # å¤šæ ‡ç­¾åˆ†ç±»
        logits = self.classification_head(reweighted_features)
        
        return {
            'logits': logits,
            'query_features': query_features,
            'dynamic_weights': dynamic_weights,
            'reweighted_features': reweighted_features
        }


# ============= æµ‹è¯•ä»£ç  =============
if __name__ == '__main__':
    import time
    
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"Device: {device}")
    
    # åˆ›å»ºæ¨¡å‹
    model = OptimizedMultiMetaFingerNet(
        num_classes=60,
        dropout=0.15,
        use_cross_attention=False,
        num_topm_layers=2,
        meta_learnet_type='lightweight'
    ).to(device)
    
    # æ¨¡æ‹Ÿè¾“å…¥
    batch_size = 32
    num_classes = 60
    shots = 20
    query_length = 20000
    support_length = 10000
    
    query_data = torch.randn(batch_size, query_length).to(device)
    support_data = torch.randn(num_classes, shots, support_length).to(device)
    support_masks = torch.ones_like(support_data)
    
    # Warmup
    for _ in range(3):
        with torch.no_grad():
            _ = model(query_data, support_data, support_masks)
    
    # æµ‹è¯•é€Ÿåº¦
    torch.cuda.synchronize()
    start = time.time()
    n_iters = 10
    for _ in range(n_iters):
        with torch.no_grad():
            output = model(query_data, support_data, support_masks)
    torch.cuda.synchronize()
    elapsed = time.time() - start
    
    print(f"\nâ±ï¸ æ¨ç†é€Ÿåº¦æµ‹è¯•:")
    print(f"  - {n_iters} æ¬¡è¿­ä»£è€—æ—¶: {elapsed:.3f}s")
    print(f"  - å¹³å‡æ¯æ¬¡: {elapsed/n_iters*1000:.1f}ms")
    print(f"  - Output shape: {output['logits'].shape}")



